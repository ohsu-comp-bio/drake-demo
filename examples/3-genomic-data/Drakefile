; Download expression and donor data. Note that we use "-timecheck" to disable
; timechecking. Since there are no dependencies for this task, Drake will
; download expression data from ICGC each time. By disabling this feature,
; Drake will only run this task if the output file doesn't exist.
expression.tsv <- [-timecheck]
  curl https://dcc.icgc.org/api/v1/download?fn=/current/Projects/ALL-US/exp_array.ALL-US.tsv.gz | gunzip > $OUTPUT


donors.tsv <-[-timecheck]
  curl https://dcc.icgc.org/api/v1/download?fn=/current/Projects/ALL-US/donor.ALL-US.tsv.gz | gunzip > $OUTPUT


; Join donor and expression data to use only columns we need. Note that we can
; pass in multiple upstream datasets to this task, and Drake will properly
; resolve dependencies. Also, we're using the Python protocol to work directly
; with the data. Drake will interpolate the script by converting text like
; $[INPUT0] to the name of the file that's being passed in.
dataset.tsv <- expression.tsv, donors.tsv [python]
  import pandas as pd

  # Read in data
  expression = pd.read_csv("$[INPUT0]", sep="\t", usecols=["icgc_donor_id", "submitted_sample_id", "gene_id", "normalized_expression_value"])
  donors = pd.read_csv("$[INPUT1]", sep="\t", usecols=["icgc_donor_id", "donor_sex"])

  # Merge our data together and take only one sample-gene pair.
  output = pd.\
    merge(donors, expression).\
    groupby(["submitted_sample_id", "gene_id"]).\
    first()

  del output["icgc_donor_id"]

  # Write our combined data to output
  output.to_csv("$[OUTPUT]", sep="\t") 


expression_matrix.tsv <- dataset.tsv [python]
  import pandas as pd

  input = pd.read_csv("$[INPUT]", sep="\t")

  # Pivot the dataset to create the expression matrix.
  output = input.\
    set_index(["donor_sex", "submitted_sample_id", "gene_id"]).\
    unstack("gene_id")

  # We need to flatten the hierarchy of our columns so that we get
  # gene names as our column headers
  output.columns = output.columns.get_level_values(1)

  output.to_csv("$[OUTPUT]", sep="\t")


; One pro-tip here is that using Matplotlib in a Docker container can be
; finicky since we're not running an X11 server. Make sure to use the Agg
; engine before importing Seaborn or PyPlot.
clusters.png <- expression_matrix.tsv [python]
  import pandas as pd

  # See note above!
  import matplotlib
  matplotlib.use('Agg')

  import seaborn as sns
  import matplotlib.pyplot as plt
  from sklearn import manifold

  input = pd.read_csv("$[INPUT]", sep="\t")

  gender = input.donor_sex
  del input['donor_sex']
  del input['submitted_sample_id']

  expression_matrix = input.as_matrix()

  embedder = manifold.TSNE(n_components=2, init='pca', random_state=0)

  X = embedder.fit_transform(expression_matrix)

  results = pd.DataFrame({'gender': gender, 'x': X[:,0], 'y': X[:,1]})

  fig, ax = plt.subplots()

  for name, group in results.groupby('gender'):
    ax.plot(group.x, group.y, marker='o', linestyle='', label=name)

  ax.legend()

  plt.savefig("$[OUTPUT]")

structured_heatmap.png <- expression_matrix.tsv [python]
  import pandas as pd

  # See note above!
  import matplotlib
  matplotlib.use('Agg')

  import seaborn as sns

  data = pd.read_csv("$[INPUT]", sep="\t")

  gender = data['donor_sex']
  del data['donor_sex']
  del data['submitted_sample_id']

  gender_pal = sns.cubehelix_palette(2)
  gender_lut = {"male": gender_pal[0], "female": gender_pal[1]}
  gender_colors = gender.map(gender_lut)

  cmap = sns.diverging_palette(h_neg=210, h_pos=350, s=90, l=30, as_cmap=True)

  sns.clustermap(data.transpose().corr(), row_colors=gender_colors, col_colors=gender_colors, cmap=cmap)

  sns.plt.savefig("$[OUTPUT]")
